# Akuma One Shot

Akuma AI is a **simple single-prompt text generation tool** powered by **Hugging Face LLMs**.  
You type a prompt, Akuma gives an AI-generated response‚Äîno chat history, no memory, just clean and simple AI responses.  

This was my first experiment with Hugging Face APIs, making it a great **starter project** for anyone exploring LLMs.

---

## üöÄ Features
- ‚úçÔ∏è Enter a prompt and get an AI-generated response
- ‚ö° Powered by Hugging Face's `Qwen3-Coder-480B-A35B-Instruct` model
- üé® Custom UI with background image styling
- üß© Minimal setup‚Äîgreat for beginners

---

## üõ†Ô∏è Tech Stack
- **Python**
- **Streamlit**
- **LangChain**
- **Hugging Face Hub**

---

## ‚öôÔ∏è Installation & Setup

### 1Ô∏è‚É£ Clone the repository
```bash
git clone https://github.com/Arsalan692/Akuma-One-Shot
cd Akuma-One-Shot
```

### 2Ô∏è‚É£ Create a virtual environment (optional but recommended)
```bash
python -m venv venv
source venv/bin/activate   # For Linux/Mac
venv\Scripts\activate      # For Windows
```

### 3Ô∏è‚É£ Install dependencies
```bash
pip install -r requirements.txt
```
### 4Ô∏è‚É£ Set up API key
**üîë Setting Up Hugging Face API Key**
- Go to **Hugging Face** and sign up for a free account: https://huggingface.co/
- After logging in, go to **Settings > Access Tokens**
- Click New Token, give it a name and choose Read permission.
- Copy the generated token.

### 5Ô∏è‚É£ Add API Key
**Create a .env file in the project root and add your key:**
```bash
# HUGGINGFACE API KEY
HUGGINGFACEHUB_API_TOKEN=your_token_here
```

### 6Ô∏è‚É£ Run the app
```bash
streamlit run akuma-one-shot.py
```
---

## üì∏ Demo Screenshot
<p align="center">
  <img src="assets/ScreenShot.png" alt="App Screenshot" width="700">
</p>
